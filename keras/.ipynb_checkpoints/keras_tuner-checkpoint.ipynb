{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introductory-copyright",
   "metadata": {},
   "source": [
    "# [Kerasチューナーの紹介](https://www.tensorflow.org/tutorials/keras/keras_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-separate",
   "metadata": {},
   "source": [
    "Keras Tunerは最適なハイパーパラメータを選択する（*hyperparameter tuning* または *hypertuning*）ためのライブラリ。\n",
    "\n",
    "ハイパーパラメータは学習をコントロールする変数であり、学習プロセスにおいて不変である。ハイパーパラメータには二つの種類がある：\n",
    "\n",
    "- モデルハイパーパラメータ（model hyperparameters）：隠れ層やユニット数などのモデルを決定づけるパラメータ\n",
    "- アルゴリズムハイパーパラメータ（algorithm hyperparameters）：学習率などの学習のスピードや質に影響するパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "difficult-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dynamic-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-renewal",
   "metadata": {},
   "source": [
    "Keras Tunerを使って最適なハイパーパラメータを見つける。ここではFashion MNISTデータセットを使って、服の画像データを分類する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alleged-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-arbor",
   "metadata": {},
   "source": [
    "ハイパーチューニングを行うには、モデルの構造に加えてハイパーパラメータの探索空間も定義する必要がある。ハイパーチューニングを行うためのモデルを**ハイパーモデル**と呼ぶ。ハイパーモデルは以下のいづれかの方法で定義できる。\n",
    "\n",
    "- モデル構築関数を使う\n",
    "- APIのクラスである`HyperModel`をサブクラス化する\n",
    "\n",
    "視覚的に行うために事前に定義された`HyperModel`クラスである、[HyperXception](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperxception-class)や[HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class)を使うこともできる。\n",
    "\n",
    "ここではモデル構築関数を使う。この関数はコンパイルされたモデルを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mobile-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32 - 512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-alfred",
   "metadata": {},
   "source": [
    "ハイパーモデルをインスタンス化する。Keras Tunerには４つのモデル（`RandomSearch`, `Hyperband`, `BayesianOptimization`, `Sklearn`）がある。ここでは`Hyperband`チューナーを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "harmful-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-filename",
   "metadata": {},
   "source": [
    "Hyperbandチューニングでは、たくさんのモデルを小さいエポックで訓練し、パフォーマンスがより良かった上位半分のモデルを次のラウンドに出場させる。ハイパーパラメータの探索を始める前に、コールバックを定義して、各トレーニングステップごとに出力をクリアするようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genuine-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-fluid",
   "metadata": {},
   "source": [
    "ハイパーパラメータ探索を実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beautiful-agency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.8666999936103821\n",
      "\n",
      "Best val_accuracy So Far: 0.8894000053405762\n",
      "Total elapsed time: 00h 06m 50s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Hyperband' object has no attribute 'get_best_hyperprarameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a6f1a6afc742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbest_hps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperprarameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m print(f\"\"\"\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Hyperband' object has no attribute 'get_best_hyperprarameters'"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    img_train,\n",
    "    label_train,\n",
    "    epochs=10,\n",
    "    validation_data=(img_test, label_test),\n",
    "    callbacks=[ClearTrainingOutput()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confirmed-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 224 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-internet",
   "metadata": {},
   "source": [
    "ハイパーパラメータのチューニングが終わったら、ついにモデルの学習である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "destroyed-crowd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6055 - accuracy: 0.7876 - val_loss: 0.4090 - val_accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3727 - accuracy: 0.8646 - val_loss: 0.4023 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.8775 - val_loss: 0.3744 - val_accuracy: 0.8626\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3048 - accuracy: 0.8884 - val_loss: 0.4107 - val_accuracy: 0.8530\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2877 - accuracy: 0.8933 - val_loss: 0.3640 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2711 - accuracy: 0.8990 - val_loss: 0.3458 - val_accuracy: 0.8777\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2584 - accuracy: 0.9052 - val_loss: 0.3219 - val_accuracy: 0.8836\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2403 - accuracy: 0.9122 - val_loss: 0.3647 - val_accuracy: 0.8765\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2340 - accuracy: 0.9130 - val_loss: 0.3537 - val_accuracy: 0.8743\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2235 - accuracy: 0.9149 - val_loss: 0.3446 - val_accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1690585e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(img_train, label_train, epochs=10, validation_data=(img_test, label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-zealand",
   "metadata": {},
   "source": [
    "チューナーをインスタンス化した時に設定した`my_dir/intro_to_kit`ディレクトリには、ハイパーパラメータ探索中に出力されたログやチェックポイントの詳細が保存されている。再度ハイパーチューニングを行なった場合には、このディレクトリから現在の状態を読み込み、探索が途中から再開される。始めからチューニングを行いたい場合は、チューナーをインスタンス化する時に`overwrite=True`とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-client",
   "metadata": {},
   "source": [
    "まとめ\n",
    "\n",
    "最適なハイパーパラメータを見つけるための、Keras Tunerの使い方について紹介した。より詳しく知りたい場合は：\n",
    "- [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
    "- [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
    "\n",
    "また、インタラクティブにハイパーパラメータを調節したい場合には、TensorBoardにある[HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)を参考にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-third",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
