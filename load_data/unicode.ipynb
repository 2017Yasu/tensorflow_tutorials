{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-beauty",
   "metadata": {},
   "source": [
    "# [Unicode 文字列](https://www.tensorflow.org/tutorials/load_data/unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-sleeve",
   "metadata": {},
   "source": [
    "Unicodeはほぼ全ての言語の文字を表すことができ、それぞれの文字は`0`から`0x10FFFF`までの整数コードに割り振られている。\n",
    "\n",
    "ここでは、Unicode文字列をTensorFlowで扱ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pacific-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-asset",
   "metadata": {},
   "source": [
    "TensorFlowでは、デフォルトでUnicodeはutf-8を用いて暗号化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-impact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks 😊\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-broadcasting",
   "metadata": {},
   "source": [
    "`tf.string`は長さの違うバイト文字列を保持することができる。したがって、文字列の長さはテンソルの次元には含まれない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "changed-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-refund",
   "metadata": {},
   "source": [
    "## Unicode を表現する\n",
    "\n",
    "TensorFlowでUnicode文字列を表現するには、以下の二つの基本的な方法がある：\n",
    "\n",
    "- `string` scalar：[character encoding](https://en.wikipedia.org/wiki/Character_encoding)を使ってバイト列を暗号化する。\n",
    "- `int32` vector：それぞれの要素が一つのコードを表す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developmental-approval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"言語処理\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8a\\x00\\x8a\\x9eQ\\xe6t\\x06'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"言語処理\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acknowledged-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35328, 35486, 20966, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"言語処理\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-french",
   "metadata": {},
   "source": [
    "TensorFlowは次の三つの異なる表現方法間で変換が可能である：\n",
    "\n",
    "- `tf.strings.unicode_decode`：暗号化された文字列スカラーをコードポイントのベクトルに変換\n",
    "- `tf.strings.unicode_encode`：コードポイントのベクトルを暗号化された文字列スカラーに変換\n",
    "- `tf.strings.unicode_transcode`：暗号化された文字列スカラーを他の暗号化手法に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35328, 35486, 20966, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driven-brief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8a\\x00\\x8a\\x9eQ\\xe6t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                            input_encoding='UTF-8',\n",
    "                            output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-accountability",
   "metadata": {},
   "source": [
    "複数の文字列をデコードする時、それぞれの文字列の長さは等しくない場合がある。バッチした時`tf.RaggedTensor`が返され、最下層の次元は文字列の長さによって決まる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'hÃllo',  u'What is the weather tomorrow',  u'Göödnight', u'😊']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-puppy",
   "metadata": {},
   "source": [
    "この`tf.RaggedTensor`を直接使うこともできるし、`tf.RaggedTensor.to_tensor`メソッドを使ってパディングされた密な`tf.Tensor`に変換することもできるし、`tf.RaggedTensor.to_sparse`メソッドを使って`tf.SparseTensor`に変換することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selective-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legendary-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-secretariat",
   "metadata": {},
   "source": [
    "長さの等しい複数の文字列を暗号化する時、`tf.Tensor`がインプットとして使われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continent-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    [[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-rings",
   "metadata": {},
   "source": [
    "長さの異なる複数の文字列を暗号化する時、`tf.RaggedTensor`を入力する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-dietary",
   "metadata": {},
   "source": [
    "パディングされた文字列またはスパースな文字列を扱う場合は、`unicode_encode`を呼び出す前に`tf.RaggedTensor`に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minus-space",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "military-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-orientation",
   "metadata": {},
   "source": [
    "## Unicode 操作\n",
    "\n",
    "文字列の長さは`tf.strings.length`を使って求める。引数`unit`を指定することで、暗号化された`string`の文字列を正しくカウントできる（デフォルトで`\"BYTE\"`、そのほかに`\"UTF8_CHAR\"`と`\"UTF16_CHAR\"`を渡すことができる）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "crazy-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks 😊'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-railway",
   "metadata": {},
   "source": [
    "部分文字列は`tf.strings.substr`を使って求める。`tf.strings.length`同様、`unit`引数を受け取る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dated-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: unit='BYTE'. With len=1, we rturn a single byte.\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "composite-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', we return a single character, which in this case is 4 bytes.\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-graduation",
   "metadata": {},
   "source": [
    "`tf.strings.unicode_split`はUnicode文字列を一文字ずつに分割する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interracial-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-bride",
   "metadata": {},
   "source": [
    "文字列テンソルを整列するためにそれぞれの文字が始まる位置のオフセットを得る。`tf.strings.unicode_decode_with_offsets`は`unicode_decode`とほぼ同じで、加えてオフセットを二つ目のテンソルとして返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "biblical-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"🎈🎉🎊\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-savings",
   "metadata": {},
   "source": [
    "## Unicode スクリプト\n",
    "\n",
    "それぞれのユニコードのコードポイントはスクリプトという集合に含まれる。TensorFlowでは`tf.strings.unicode_script`メソッドを使って、どのスクリプトを与えられたコードポイントが利用しているかを特定できる。スクリプトのコードは整数値で、[International Components for Unicode (ICU)](http://site.icu-project.org/home)値`UScriptCode`に対応する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thirty-reaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['芸', 'Б']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "foreign-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "# The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensor`s\n",
    "# or `tf.RaggedTensor`s of codepoints:\n",
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-supervision",
   "metadata": {},
   "source": [
    "## 例：単純なセグメンテーション\n",
    "\n",
    "ここでのセグメンテーションは単語単位にテキストを分割すること。スクリプトの変化を使って単語の境を近似的に求めることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "athletic-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'世界こんにちは']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-physics",
   "metadata": {},
   "source": [
    "まずはじめに、文章を文字コードポイントにデコードし、それぞれの文字についてスクリプトの識別子を見つける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "earlier-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-database",
   "metadata": {},
   "source": [
    "次に、これらのスクリプト識別子を使って、単語の境をどこに入れるべきかを決定する。これは先頭とスクリプトが変化する位置に追加される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numeric-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-siemens",
   "metadata": {},
   "source": [
    "これらの開始オフセットを使って、全てのバッチから得られる単語のリストを含んだ`RaggedTensor`を構築する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "biological-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts\n",
    ")\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-oliver",
   "metadata": {},
   "source": [
    "結果として、単語のコードポイント`RaggedTensor`を文章にセグメントできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dental-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-renaissance",
   "metadata": {},
   "source": [
    "最終結果を読みやすい形に変換できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pursuant-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-stationery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
