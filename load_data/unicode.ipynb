{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-beauty",
   "metadata": {},
   "source": [
    "# [Unicode æ–‡å­—åˆ—](https://www.tensorflow.org/tutorials/load_data/unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-sleeve",
   "metadata": {},
   "source": [
    "Unicodeã¯ã»ã¼å…¨ã¦ã®è¨€èªã®æ–‡å­—ã‚’è¡¨ã™ã“ã¨ãŒã§ãã€ãã‚Œãã‚Œã®æ–‡å­—ã¯`0`ã‹ã‚‰`0x10FFFF`ã¾ã§ã®æ•´æ•°ã‚³ãƒ¼ãƒ‰ã«å‰²ã‚ŠæŒ¯ã‚‰ã‚Œã¦ã„ã‚‹ã€‚\n",
    "\n",
    "ã“ã“ã§ã¯ã€Unicodeæ–‡å­—åˆ—ã‚’TensorFlowã§æ‰±ã£ã¦ã¿ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pacific-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-asset",
   "metadata": {},
   "source": [
    "TensorFlowã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Unicodeã¯utf-8ã‚’ç”¨ã„ã¦æš—å·åŒ–ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-impact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks ğŸ˜Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-broadcasting",
   "metadata": {},
   "source": [
    "`tf.string`ã¯é•·ã•ã®é•ã†ãƒã‚¤ãƒˆæ–‡å­—åˆ—ã‚’ä¿æŒã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã—ãŸãŒã£ã¦ã€æ–‡å­—åˆ—ã®é•·ã•ã¯ãƒ†ãƒ³ã‚½ãƒ«ã®æ¬¡å…ƒã«ã¯å«ã¾ã‚Œãªã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "changed-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-refund",
   "metadata": {},
   "source": [
    "## Unicode ã‚’è¡¨ç¾ã™ã‚‹\n",
    "\n",
    "TensorFlowã§Unicodeæ–‡å­—åˆ—ã‚’è¡¨ç¾ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®äºŒã¤ã®åŸºæœ¬çš„ãªæ–¹æ³•ãŒã‚ã‚‹ï¼š\n",
    "\n",
    "- `string` scalarï¼š[character encoding](https://en.wikipedia.org/wiki/Character_encoding)ã‚’ä½¿ã£ã¦ãƒã‚¤ãƒˆåˆ—ã‚’æš—å·åŒ–ã™ã‚‹ã€‚\n",
    "- `int32` vectorï¼šãã‚Œãã‚Œã®è¦ç´ ãŒä¸€ã¤ã®ã‚³ãƒ¼ãƒ‰ã‚’è¡¨ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developmental-approval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"è¨€èªå‡¦ç†\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8a\\x00\\x8a\\x9eQ\\xe6t\\x06'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"è¨€èªå‡¦ç†\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acknowledged-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35328, 35486, 20966, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"è¨€èªå‡¦ç†\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-french",
   "metadata": {},
   "source": [
    "TensorFlowã¯æ¬¡ã®ä¸‰ã¤ã®ç•°ãªã‚‹è¡¨ç¾æ–¹æ³•é–“ã§å¤‰æ›ãŒå¯èƒ½ã§ã‚ã‚‹ï¼š\n",
    "\n",
    "- `tf.strings.unicode_decode`ï¼šæš—å·åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚¹ã‚«ãƒ©ãƒ¼ã‚’ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›\n",
    "- `tf.strings.unicode_encode`ï¼šã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’æš—å·åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚¹ã‚«ãƒ©ãƒ¼ã«å¤‰æ›\n",
    "- `tf.strings.unicode_transcode`ï¼šæš—å·åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚¹ã‚«ãƒ©ãƒ¼ã‚’ä»–ã®æš—å·åŒ–æ‰‹æ³•ã«å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35328, 35486, 20966, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driven-brief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8a\\x00\\x8a\\x9eQ\\xe6t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                            input_encoding='UTF-8',\n",
    "                            output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-accountability",
   "metadata": {},
   "source": [
    "è¤‡æ•°ã®æ–‡å­—åˆ—ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹æ™‚ã€ãã‚Œãã‚Œã®æ–‡å­—åˆ—ã®é•·ã•ã¯ç­‰ã—ããªã„å ´åˆãŒã‚ã‚‹ã€‚ãƒãƒƒãƒã—ãŸæ™‚`tf.RaggedTensor`ãŒè¿”ã•ã‚Œã€æœ€ä¸‹å±¤ã®æ¬¡å…ƒã¯æ–‡å­—åˆ—ã®é•·ã•ã«ã‚ˆã£ã¦æ±ºã¾ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'hÃƒllo',  u'What is the weather tomorrow',  u'GÃ¶Ã¶dnight', u'ğŸ˜Š']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-puppy",
   "metadata": {},
   "source": [
    "ã“ã®`tf.RaggedTensor`ã‚’ç›´æ¥ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹ã—ã€`tf.RaggedTensor.to_tensor`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸå¯†ãª`tf.Tensor`ã«å¤‰æ›ã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã—ã€`tf.RaggedTensor.to_sparse`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦`tf.SparseTensor`ã«å¤‰æ›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selective-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legendary-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-secretariat",
   "metadata": {},
   "source": [
    "é•·ã•ã®ç­‰ã—ã„è¤‡æ•°ã®æ–‡å­—åˆ—ã‚’æš—å·åŒ–ã™ã‚‹æ™‚ã€`tf.Tensor`ãŒã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continent-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    [[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-rings",
   "metadata": {},
   "source": [
    "é•·ã•ã®ç•°ãªã‚‹è¤‡æ•°ã®æ–‡å­—åˆ—ã‚’æš—å·åŒ–ã™ã‚‹æ™‚ã€`tf.RaggedTensor`ã‚’å…¥åŠ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-dietary",
   "metadata": {},
   "source": [
    "ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸæ–‡å­—åˆ—ã¾ãŸã¯ã‚¹ãƒ‘ãƒ¼ã‚¹ãªæ–‡å­—åˆ—ã‚’æ‰±ã†å ´åˆã¯ã€`unicode_encode`ã‚’å‘¼ã³å‡ºã™å‰ã«`tf.RaggedTensor`ã«å¤‰æ›ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minus-space",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "military-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-orientation",
   "metadata": {},
   "source": [
    "## Unicode æ“ä½œ\n",
    "\n",
    "æ–‡å­—åˆ—ã®é•·ã•ã¯`tf.strings.length`ã‚’ä½¿ã£ã¦æ±‚ã‚ã‚‹ã€‚å¼•æ•°`unit`ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€æš—å·åŒ–ã•ã‚ŒãŸ`string`ã®æ–‡å­—åˆ—ã‚’æ­£ã—ãã‚«ã‚¦ãƒ³ãƒˆã§ãã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§`\"BYTE\"`ã€ãã®ã»ã‹ã«`\"UTF8_CHAR\"`ã¨`\"UTF16_CHAR\"`ã‚’æ¸¡ã™ã“ã¨ãŒã§ãã‚‹ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "crazy-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks ğŸ˜Š'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-railway",
   "metadata": {},
   "source": [
    "éƒ¨åˆ†æ–‡å­—åˆ—ã¯`tf.strings.substr`ã‚’ä½¿ã£ã¦æ±‚ã‚ã‚‹ã€‚`tf.strings.length`åŒæ§˜ã€`unit`å¼•æ•°ã‚’å—ã‘å–ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dated-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: unit='BYTE'. With len=1, we rturn a single byte.\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "composite-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', we return a single character, which in this case is 4 bytes.\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-graduation",
   "metadata": {},
   "source": [
    "`tf.strings.unicode_split`ã¯Unicodeæ–‡å­—åˆ—ã‚’ä¸€æ–‡å­—ãšã¤ã«åˆ†å‰²ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interracial-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-bride",
   "metadata": {},
   "source": [
    "æ–‡å­—åˆ—ãƒ†ãƒ³ã‚½ãƒ«ã‚’æ•´åˆ—ã™ã‚‹ãŸã‚ã«ãã‚Œãã‚Œã®æ–‡å­—ãŒå§‹ã¾ã‚‹ä½ç½®ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚`tf.strings.unicode_decode_with_offsets`ã¯`unicode_decode`ã¨ã»ã¼åŒã˜ã§ã€åŠ ãˆã¦ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’äºŒã¤ç›®ã®ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "biblical-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"ğŸˆğŸ‰ğŸŠ\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-savings",
   "metadata": {},
   "source": [
    "## Unicode ã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n",
    "\n",
    "ãã‚Œãã‚Œã®ãƒ¦ãƒ‹ã‚³ãƒ¼ãƒ‰ã®ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã„ã†é›†åˆã«å«ã¾ã‚Œã‚‹ã€‚TensorFlowã§ã¯`tf.strings.unicode_script`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦ã€ã©ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒåˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã§ãã‚‹ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚³ãƒ¼ãƒ‰ã¯æ•´æ•°å€¤ã§ã€[International Components for Unicode (ICU)](http://site.icu-project.org/home)å€¤`UScriptCode`ã«å¯¾å¿œã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thirty-reaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['èŠ¸', 'Ğ‘']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "foreign-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "# The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensor`s\n",
    "# or `tf.RaggedTensor`s of codepoints:\n",
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-supervision",
   "metadata": {},
   "source": [
    "## ä¾‹ï¼šå˜ç´”ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "\n",
    "ã“ã“ã§ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯å˜èªå˜ä½ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã™ã‚‹ã“ã¨ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å¤‰åŒ–ã‚’ä½¿ã£ã¦å˜èªã®å¢ƒã‚’è¿‘ä¼¼çš„ã«æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "athletic-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'ä¸–ç•Œã“ã‚“ã«ã¡ã¯']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-physics",
   "metadata": {},
   "source": [
    "ã¾ãšã¯ã˜ã‚ã«ã€æ–‡ç« ã‚’æ–‡å­—ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã€ãã‚Œãã‚Œã®æ–‡å­—ã«ã¤ã„ã¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è­˜åˆ¥å­ã‚’è¦‹ã¤ã‘ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "earlier-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-database",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ã“ã‚Œã‚‰ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆè­˜åˆ¥å­ã‚’ä½¿ã£ã¦ã€å˜èªã®å¢ƒã‚’ã©ã“ã«å…¥ã‚Œã‚‹ã¹ãã‹ã‚’æ±ºå®šã™ã‚‹ã€‚ã“ã‚Œã¯å…ˆé ­ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå¤‰åŒ–ã™ã‚‹ä½ç½®ã«è¿½åŠ ã•ã‚Œã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numeric-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-siemens",
   "metadata": {},
   "source": [
    "ã“ã‚Œã‚‰ã®é–‹å§‹ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€å…¨ã¦ã®ãƒãƒƒãƒã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹å˜èªã®ãƒªã‚¹ãƒˆã‚’å«ã‚“ã `RaggedTensor`ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "biological-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts\n",
    ")\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-oliver",
   "metadata": {},
   "source": [
    "çµæœã¨ã—ã¦ã€å˜èªã®ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆ`RaggedTensor`ã‚’æ–‡ç« ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ãã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dental-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-renaissance",
   "metadata": {},
   "source": [
    "æœ€çµ‚çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢ã«å¤‰æ›ã§ãã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pursuant-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-stationery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
